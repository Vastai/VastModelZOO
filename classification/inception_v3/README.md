
# inception_v3

[inception_v3: Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567)


## Model Arch

### pre-processing

inception_v3ç³»åˆ—ç½‘ç»œçš„é¢„å¤„ç†æ“ä½œå¯ä»¥æŒ‰ç…§å¦‚ä¸‹æ­¥éª¤è¿›è¡Œï¼Œå³å…ˆå¯¹å›¾ç‰‡è¿›è¡Œresizeè‡³342çš„å°ºå¯¸ï¼Œç„¶ååˆ©ç”¨`CenterCrop`ç®—å­cropå‡º299çš„å›¾ç‰‡å¯¹å…¶è¿›è¡Œå½’ä¸€åŒ–ã€å‡å‡å€¼é™¤æ–¹å·®ç­‰æ“ä½œã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œinception_v3ç³»åˆ—æ‰€ç”¨åˆ°çš„å‡å€¼æ–¹å·®ä¸å…¶ä»–resnetã€vggç­‰ç½‘ç»œæ‰€ç”¨çš„å‡å€¼æ–¹å·®æœ‰æ‰€ä¸åŒ

```python
[
    torchvision.transforms.Resize(342),
    torchvision.transforms.CenterCrop(299),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5],),
]
```

### post-processing

inception_v3ç³»åˆ—ç½‘ç»œçš„åå¤„ç†æ“ä½œæ˜¯å¯¹ç½‘ç»œè¾“å‡ºè¿›è¡Œsoftmaxä½œä¸ºæ¯ä¸ªç±»åˆ«çš„é¢„æµ‹å€¼ï¼Œç„¶åæ ¹æ®é¢„æµ‹å€¼è¿›è¡Œæ’åºï¼Œé€‰æ‹©topkä½œä¸ºè¾“å…¥å›¾ç‰‡çš„é¢„æµ‹åˆ†æ•°ä»¥åŠç±»åˆ«

### backbone

inception_v3åœ¨ä¹‹å‰çš„åŸºç¡€ä¸Šå¢åŠ ï¼š
- æ ‡ç­¾å¹³æ»‘
- å°†å¤§å·ç§¯åˆ†è§£æˆå°å·ç§¯ï¼Œä½¿å¾—åœ¨æ„Ÿå—é‡ä¸å˜çš„æƒ…å†µä¸‹ï¼Œå‡å°‘å‚æ•°çš„è®¡ç®—é‡
- max poolingå±‚åœ¨ä¸‹é‡‡æ ·ä¼šå¯¼è‡´ä¿¡æ¯æŸå¤±å¤§ï¼Œäºæ˜¯è®¾è®¡æˆè®¡ç®—è¾“å…¥Açš„å·ç§¯ç»“æœï¼Œè®¡ç®—è¾“å…¥Açš„poolingç»“æœï¼Œå¹¶ä¸”å°†å·ç§¯çš„ç»“æœä¸æ± åŒ–çš„ç»“æœconcatã€‚è¿™æ ·å‡å°‘è®¡ç®—é‡åˆå‡å°‘ä¿¡æ¯æŸå¤±ã€‚

<div align=center><img src="../../images/inceptionv3/inceptionv3.png" width="50%" height="50%"></div>

### head

inception_v3ç³»åˆ—ç½‘ç»œçš„headå±‚ç”±global-average-poolingå±‚å’Œä¸€å±‚å…¨è¿æ¥å±‚ç»„æˆ

### common

- inception_v3æ¶æ„

## Model Info

### æ¨¡å‹æ€§èƒ½

|        æ¨¡å‹        |                                               æºç                                                 |  top1  |  top5  | flops(G) | params(M) | input size |
| :----------------: | :-----------------------------------------------------------------------------------------------: | :----: | :----: | :------: | :-------: | :--------: |
|    inception_v3    |   [torchvision](https://github.com/pytorch/vision/blob/v0.9.0/torchvision/models/inception.py)    | 77.294 | 93.450 |  11.021  |  27.200   |    299     |
|    inception_v3    | [timm](https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/inception_v3.py) | 77.438 | 93.476 |  11.498  |  23.830   |    299     |
|  tf_inception_v3   | [timm](https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/inception_v3.py) | 77.852 | 93.640 |  11.498  |  23.830   |    299     |
|  adv_inception_v3  | [timm](https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/inception_v3.py) | 77.578 | 93.738 |  11.498  |  23.830   |    299     |
| gluon_inception_v3 | [timm](https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/inception_v3.py) | 78.806 | 94.370 |  11.498  |  23.830   |    299     |
|    inception_v3    |  [ppcls](https://github.com/PaddlePaddle/PaddleClas/blob/v2.4.0/docs/zh_CN/models/Inception.md)   | 79.100 | 94.600 |  11.460  |  23.830   |    299     |

### æµ‹è¯„æ•°æ®é›†è¯´æ˜

<div align=center><img src="../../images/datasets/imagenet.jpg"></div>

[ImageNet](https://image-net.org) æ˜¯ä¸€ä¸ªè®¡ç®—æœºè§†è§‰ç³»ç»Ÿè¯†åˆ«é¡¹ç›®ï¼Œæ˜¯ç›®å‰ä¸–ç•Œä¸Šå›¾åƒè¯†åˆ«æœ€å¤§çš„æ•°æ®åº“ã€‚æ˜¯ç¾å›½æ–¯å¦ç¦çš„è®¡ç®—æœºç§‘å­¦å®¶ï¼Œæ¨¡æ‹Ÿäººç±»çš„è¯†åˆ«ç³»ç»Ÿå»ºç«‹çš„ã€‚èƒ½å¤Ÿä»å›¾ç‰‡ä¸­è¯†åˆ«ç‰©ä½“ã€‚ImageNetæ˜¯ä¸€ä¸ªéå¸¸æœ‰å‰æ™¯çš„ç ”ç©¶é¡¹ç›®ï¼Œæœªæ¥ç”¨åœ¨æœºå™¨äººèº«ä¸Šï¼Œå°±å¯ä»¥ç›´æ¥è¾¨è®¤ç‰©å“å’Œäººäº†ã€‚è¶…è¿‡1400ä¸‡çš„å›¾åƒURLè¢«ImageNetæ‰‹åŠ¨æ³¨é‡Šï¼Œä»¥æŒ‡ç¤ºå›¾ç‰‡ä¸­çš„å¯¹è±¡;åœ¨è‡³å°‘ä¸€ç™¾ä¸‡å¼ å›¾åƒä¸­ï¼Œè¿˜æä¾›äº†è¾¹ç•Œæ¡†ã€‚ImageNetåŒ…å«2ä¸‡å¤šä¸ªç±»åˆ«; ä¸€ä¸ªå…¸å‹çš„ç±»åˆ«ï¼Œå¦‚â€œæ°”çƒâ€æˆ–â€œè‰è“â€ï¼Œæ¯ä¸ªç±»åŒ…å«æ•°ç™¾å¼ å›¾åƒã€‚

ImageNetæ•°æ®æ˜¯CVé¢†åŸŸéå¸¸å‡ºåçš„æ•°æ®é›†ï¼ŒISLVRCç«èµ›ä½¿ç”¨çš„æ•°æ®é›†æ˜¯è½»é‡ç‰ˆçš„ImageNetæ•°æ®é›†ã€‚ISLVRC2012æ˜¯éå¸¸å‡ºåçš„ä¸€ä¸ªæ•°æ®é›†ï¼Œåœ¨å¾ˆå¤šCVé¢†åŸŸçš„è®ºæ–‡ï¼Œéƒ½ä¼šä½¿ç”¨è¿™ä¸ªæ•°æ®é›†å¯¹è‡ªå·±çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•ï¼Œåœ¨è¯¥é¡¹ç›®ä¸­åˆ†ç±»ç®—æ³•ç”¨åˆ°çš„æµ‹è¯„æ•°æ®é›†å°±æ˜¯ISLVRC2012æ•°æ®é›†çš„éªŒè¯é›†ã€‚åœ¨ä¸€äº›è®ºæ–‡ä¸­ï¼Œä¹Ÿä¼šç§°è¿™ä¸ªæ•°æ®å«æˆImageNet 1Kæˆ–è€…ISLVRC2012ï¼Œä¸¤è€…æ˜¯ä¸€æ ·çš„ã€‚â€œ1 Kâ€ä»£è¡¨çš„æ˜¯1000ä¸ªç±»åˆ«ã€‚

### è¯„ä»·æŒ‡æ ‡è¯´æ˜

- top1å‡†ç¡®ç‡: æµ‹è¯•å›¾ç‰‡ä¸­æœ€ä½³å¾—åˆ†æ‰€å¯¹åº”çš„æ ‡ç­¾æ˜¯æ­£ç¡®æ ‡æ³¨ç±»åˆ«çš„æ ·æœ¬æ•°é™¤ä»¥æ€»çš„æ ·æœ¬æ•°
- top5å‡†ç¡®ç‡: æµ‹è¯•å›¾ç‰‡ä¸­æ­£ç¡®æ ‡ç­¾åŒ…å«åœ¨å‰äº”ä¸ªåˆ†ç±»æ¦‚ç‡ä¸­çš„ä¸ªæ•°é™¤ä»¥æ€»çš„æ ·æœ¬æ•°

## Deploy
ğŸ“ æ³¨ï¼šè¯¥ç½‘ç»œä»…åœ¨`step.1 & step.3`éƒ¨åˆ†æœ‰åŒºåˆ«

### step.1 è·å–æ¨¡å‹

1. timm

    ```bash
    pip install timm==0.6.5
    python ../common/utils/export_timm_torchvision_model.py --model_library timm  --model_name inception_v3 --save_dir ./onnx  --size 299 --pretrained_weights xxx.pth
    ```
2. torchvision

    ```bash
    python ../common/utils/export_timm_torchvision_model.py --model_library torchvision  --model_name inception_v3 --save_dir ./onnx  --size 299 --pretrained_weights xxx.pth
    ```


3. ppcls

   ```bash
    pip install PaddlePaddle==2.3.2  Paddle2ONNX==1.0.0
    paddle2onnx  --model_dir /path/to/inceptionv3_paddle_model/ \
                --model_filename model.pdmodel \
                --params_filename model.pdiparams \
                --save_file model.onnx \
                --enable_dev_version False \
                --opset_version 10
    ```

### step.2 è·å–æ•°æ®é›†
- æœ¬æ¨¡å‹ä½¿ç”¨ImageNetå®˜ç½‘ILSVRC2012çš„5ä¸‡å¼ éªŒè¯é›†è¿›è¡Œæµ‹è¯•ï¼Œé’ˆå¯¹`int8`æ ¡å‡†æ•°æ®å¯ä»è¯¥æ•°æ®é›†ä¸­ä»»é€‰1000å¼ ï¼Œä¸ºäº†ä¿è¯é‡åŒ–ç²¾åº¦ï¼Œè¯·ä¿è¯æ¯ä¸ªç±»åˆ«éƒ½æœ‰æ•°æ®ï¼Œè¯·ç”¨æˆ·è‡ªè¡Œè·å–è¯¥æ•°æ®é›†ï¼Œ[ILSVRC2012](https://image-net.org/challenges/LSVRC/2012/index.php)

    ```
    â”œâ”€â”€ ImageNet
    |   â”œâ”€â”€ val
    |   |    â”œâ”€â”€ ILSVRC2012_val_00000001.JPEG
    â”‚   |    â”œâ”€â”€ ILSVRC2012_val_00000002.JPEG
    â”‚   |    â”œâ”€â”€ ......
    |   â”œâ”€â”€ val_label.txt
    ```

    ```bash
    sh ./data_prep_sh_files/valprep.sh
    ```

    ```bash
    # label.txt
    tench, Tinca tinca
    goldfish, Carassius auratus
    ...
    ```

### step.3 æ¨¡å‹è½¬æ¢

1. ä½¿ç”¨æ¨¡å‹è½¬æ¢å·¥å…·vamc, æ ¹æ®å…·ä½“æ¨¡å‹ä¿®æ”¹æ¨¡å‹è½¬æ¢é…ç½®æ–‡ä»¶, æ­¤å¤„ä»¥`timm` ä¸ºä¾‹
    ```bash
    vamc build ./vacc_code/build/timm_inceptionv3.yaml
    ```
    - [timm](./vacc_code/build/timm_inceptionv3.yaml)
    - [torchvision](./vacc_code/build/torchvision_inceptionv3.yaml)
    - [ppcls](./vacc_code/build/ppcls_inceptionv3.yaml)


### step.4 benchmark
1. ç”Ÿæˆæ¨ç†æ•°æ®`npz`ä»¥åŠå¯¹åº”çš„`datalist.txt`
    ```bash
    python ../common/utils/image2npz.py --dataset_path /path/to/ILSVRC2012_img_val --target_path  /path/to/input_npz  --text_path npz_datalist.txt
    ```
2. æ€§èƒ½æµ‹è¯•
    ```bash
    ./vamp -m inception_v3-int8-percentile-3_299_299-vacc/inception_v3 --vdsp_params ./vacc_code/vdsp_params/timm-inception_v3-vdsp_params.json  -i 8 -p 1 -b 22
    ```
    
3. è·å–ç²¾åº¦ä¿¡æ¯
    ```bash
    ./vamp -m inception_v3-int8-percentile-3_299_299-vacc/inception_v3 --vdsp_params ./vacc_code/vdsp_params/timm-inception_v3-vdsp_params.json  -i 8 -p 1 -b 22 --datalist npz_datalist.txt --path_output output
    ```
4. ç»“æœè§£æåŠç²¾åº¦è¯„ä¼°
    ```bash
    python ../common/eval/vamp_eval.py --result_path output  --datalist npz_datalist.txt --label data/label/imagenet.txt
    ```