
# HRNet

[Deep High-Resolution Representation Learning for Visual Recognition](https://arxiv.org/pdf/1908.07919.pdf)


## Model Arch

<div align=center><img src="../../images/hrnet/cls-hrnet.png"></div>

### pre-processing

HRNetç³»åˆ—ç½‘ç»œçš„é¢„å¤„ç†æ“ä½œå¯ä»¥æŒ‰ç…§å¦‚ä¸‹æ­¥éª¤è¿›è¡Œï¼Œå³å…ˆå¯¹å›¾ç‰‡è¿›è¡Œresizeè‡³256çš„å°ºå¯¸ï¼Œç„¶ååˆ©ç”¨`CenterCrop`ç®—å­cropå‡º224çš„å›¾ç‰‡å¯¹å…¶è¿›è¡Œå½’ä¸€åŒ–ã€å‡å‡å€¼é™¤æ–¹å·®ç­‰æ“ä½œ

```python
[
    torchvision.transforms.Resize(256),
    torchvision.transforms.CenterCrop(224),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225],),
]
```

### post-processing

HRNetç³»åˆ—ç½‘ç»œçš„åå¤„ç†æ“ä½œæ˜¯å¯¹ç½‘ç»œè¾“å‡ºè¿›è¡Œsoftmaxä½œä¸ºæ¯ä¸ªç±»åˆ«çš„é¢„æµ‹å€¼ï¼Œç„¶åæ ¹æ®é¢„æµ‹å€¼è¿›è¡Œæ’åºï¼Œé€‰æ‹©topkä½œä¸ºè¾“å…¥å›¾ç‰‡çš„é¢„æµ‹åˆ†æ•°ä»¥åŠç±»åˆ«

### backbone

HRNetç½‘ç»œæ˜¯å°†ä¸åŒåˆ†è¾¨ç‡çš„feature mapè¿›è¡Œå¹¶è”ï¼Œåœ¨å¹¶è”çš„åŸºç¡€ä¸Šæ·»åŠ ä¸åŒåˆ†è¾¨ç‡feature mapä¹‹é—´çš„èåˆï¼Œå…·ä½“èåˆçš„æ–¹æ³•å¯ä»¥åˆ†ä¸º4ç§ï¼š

1. åŒåˆ†è¾¨ç‡çš„å±‚ç›´æ¥å¤åˆ¶
2. éœ€è¦å‡åˆ†è¾¨ç‡çš„ä½¿ç”¨bilinear upsample + 1x1å·ç§¯å°†channelæ•°ç»Ÿä¸€
3. éœ€è¦é™åˆ†è¾¨ç‡çš„ä½¿ç”¨strideä¸º2çš„3x3 å·ç§¯
4. ä¸‰ä¸ªfeature mapèåˆçš„æ–¹å¼æ˜¯ç›¸åŠ 

é€šè¿‡ä¸Šè¿°è§„åˆ™ç”Ÿæˆäº†ä¸€ç³»åˆ—ç‰¹å¾å±‚çš„ç»„åˆï¼Œç„¶åé€‰æ‹©ç›¸åº”çš„ç‰¹å¾ç»„åˆï¼Œå³ç»„æˆäº†åŸºäºHRNetç®—æ³•çš„åˆ†ç±»ç½‘ç»œ

### head

HRNetç³»åˆ—ç½‘ç»œçš„headå±‚ç”±global-average-poolingå±‚å’Œä¸€å±‚å…¨è¿æ¥å±‚ç»„æˆ

### common

- bilinear upsample

## Model Info

### æ¨¡å‹æ€§èƒ½

|           æ¨¡å‹           |                                                æºç                                                  |  top1  |  top5  | flops(G) | params(M) | input size |
| :----------------------: | :-------------------------------------------------------------------------------------------------: | :----: | :----: | :------: | :-------: | :--------: |
| HRNet_w18_small_model_v1 |                   [official](https://github.com/HRNet/HRNet-Image-Classification)                   |  72.3  |  90.7  |   1.49   |   13.2    |    224     |
| HRNet_w18_small_model_v2 |                   [official](https://github.com/HRNet/HRNet-Image-Classification)                   |  75.1  |  92.4  |   2.42   |   15.6    |    224     |
|        HRNet_w18         |                   [official](https://github.com/HRNet/HRNet-Image-Classification)                   |  76.8  |  93.3  |   3.99   |   21.3    |    224     |
|        HRNet_w30         |                   [official](https://github.com/HRNet/HRNet-Image-Classification)                   |  78.2  |  94.2  |   7.55   |   37.7    |    224     |
|        HRNet_w32         |                   [official](https://github.com/HRNet/HRNet-Image-Classification)                   |  78.5  |  94.2  |   8.31   |   41.2    |    224     |
|        HRNet_w40         |                   [official](https://github.com/HRNet/HRNet-Image-Classification)                   |  78.9  |  94.5  |   11.8   |   57.6    |    224     |
|        HRNet_w44         |                   [official](https://github.com/HRNet/HRNet-Image-Classification)                   |  78.9  |  94.4  |   13.9   |   67.1    |    224     |
|        HRNet_w48         |                   [official](https://github.com/HRNet/HRNet-Image-Classification)                   |  79.3  |  94.5  |   16.1   |   77.5    |    224     |
|        HRNet_w64         |                   [official](https://github.com/HRNet/HRNet-Image-Classification)                   |  79.5  |  94.6  |   26.9   |   128.1   |    224     |
|        HRNet_w18         | [mmcls](https://github.com/open-mmlab/mmclassification/blob/master/mmcls/models/backbones/hrnet.py) | 76.75  | 93.44  |   4.33   |   21.30   |    224     |
|        HRNet_w30         | [mmcls](https://github.com/open-mmlab/mmclassification/blob/master/mmcls/models/backbones/hrnet.py) | 78.19  | 94.22  |   8.17   |   37.71   |    224     |
|        HRNet_w32         | [mmcls](https://github.com/open-mmlab/mmclassification/blob/master/mmcls/models/backbones/hrnet.py) | 78.44  | 94.19  |   8.99   |   41.23   |    224     |
|        HRNet_w40         | [mmcls](https://github.com/open-mmlab/mmclassification/blob/master/mmcls/models/backbones/hrnet.py) | 78.94  | 94.47  |  12.77   |   57.55   |    224     |
|        HRNet_w44         | [mmcls](https://github.com/open-mmlab/mmclassification/blob/master/mmcls/models/backbones/hrnet.py) | 78.88  | 94.37  |  14.96   |   67.06   |    224     |
|        HRNet_w48         | [mmcls](https://github.com/open-mmlab/mmclassification/blob/master/mmcls/models/backbones/hrnet.py) | 79.32  | 94.52  |  17.36   |   77.47   |    224     |
|        HRNet_w64         | [mmcls](https://github.com/open-mmlab/mmclassification/blob/master/mmcls/models/backbones/hrnet.py) | 79.46  | 94.65  |  29.00   |  128.06   |    224     |
|    hrnet_w18_small_v1    |     [timm](https://github.com/rwightman/pytorch-image-models/blob/v0.6.5/timm/models/hrnet.py)      | 72.336 | 90.68  |  3.611   |  13.187   |    224     |
|    hrnet_w18_small_v2    |     [timm](https://github.com/rwightman/pytorch-image-models/blob/v0.6.5/timm/models/hrnet.py)      | 75.11  | 92.416 |  5.856   |  15.597   |    224     |
|        hrnet_w18         |     [timm](https://github.com/rwightman/pytorch-image-models/blob/v0.6.5/timm/models/hrnet.py)      | 76.76  | 93.444 |  9.667   |  21.299   |    224     |
|        hrnet_w30         |     [timm](https://github.com/rwightman/pytorch-image-models/blob/v0.6.5/timm/models/hrnet.py)      | 78.198 | 94.224 |  18.207  |  37.712   |    224     |
|        hrnet_w32         |     [timm](https://github.com/rwightman/pytorch-image-models/blob/v0.6.5/timm/models/hrnet.py)      | 78.452 | 94.188 |  20.026  |  41.233   |    224     |
|        hrnet_w40         |     [timm](https://github.com/rwightman/pytorch-image-models/blob/v0.6.5/timm/models/hrnet.py)      | 78.922 | 94.47  |  28.436  |  57.557   |    224     |
|        hrnet_w44         |     [timm](https://github.com/rwightman/pytorch-image-models/blob/v0.6.5/timm/models/hrnet.py)      | 78.896 | 94.37  |  33.320  |  67.065   |    224     |
|        hrnet_w48         |     [timm](https://github.com/rwightman/pytorch-image-models/blob/v0.6.5/timm/models/hrnet.py)      |  79.3  | 94.514 |  38.658  |  77.470   |    224     |
|        hrnet_w64         |     [timm](https://github.com/rwightman/pytorch-image-models/blob/v0.6.5/timm/models/hrnet.py)      | 79.47  | 94.654 |  64.535  |  128.060  |    224     |

### æµ‹è¯„æ•°æ®é›†è¯´æ˜

<div align=center><img src="../../images/datasets/imagenet.jpg"></div>

[ImageNet](https://image-net.org) æ˜¯ä¸€ä¸ªè®¡ç®—æœºè§†è§‰ç³»ç»Ÿè¯†åˆ«é¡¹ç›®ï¼Œæ˜¯ç›®å‰ä¸–ç•Œä¸Šå›¾åƒè¯†åˆ«æœ€å¤§çš„æ•°æ®åº“ã€‚æ˜¯ç¾å›½æ–¯å¦ç¦çš„è®¡ç®—æœºç§‘å­¦å®¶ï¼Œæ¨¡æ‹Ÿäººç±»çš„è¯†åˆ«ç³»ç»Ÿå»ºç«‹çš„ã€‚èƒ½å¤Ÿä»å›¾ç‰‡ä¸­è¯†åˆ«ç‰©ä½“ã€‚ImageNetæ˜¯ä¸€ä¸ªéå¸¸æœ‰å‰æ™¯çš„ç ”ç©¶é¡¹ç›®ï¼Œæœªæ¥ç”¨åœ¨æœºå™¨äººèº«ä¸Šï¼Œå°±å¯ä»¥ç›´æ¥è¾¨è®¤ç‰©å“å’Œäººäº†ã€‚è¶…è¿‡1400ä¸‡çš„å›¾åƒURLè¢«ImageNetæ‰‹åŠ¨æ³¨é‡Šï¼Œä»¥æŒ‡ç¤ºå›¾ç‰‡ä¸­çš„å¯¹è±¡;åœ¨è‡³å°‘ä¸€ç™¾ä¸‡å¼ å›¾åƒä¸­ï¼Œè¿˜æä¾›äº†è¾¹ç•Œæ¡†ã€‚ImageNetåŒ…å«2ä¸‡å¤šä¸ªç±»åˆ«; ä¸€ä¸ªå…¸å‹çš„ç±»åˆ«ï¼Œå¦‚â€œæ°”çƒâ€æˆ–â€œè‰è“â€ï¼Œæ¯ä¸ªç±»åŒ…å«æ•°ç™¾å¼ å›¾åƒã€‚

ImageNetæ•°æ®æ˜¯CVé¢†åŸŸéå¸¸å‡ºåçš„æ•°æ®é›†ï¼ŒISLVRCç«èµ›ä½¿ç”¨çš„æ•°æ®é›†æ˜¯è½»é‡ç‰ˆçš„ImageNetæ•°æ®é›†ã€‚ISLVRC2012æ˜¯éå¸¸å‡ºåçš„ä¸€ä¸ªæ•°æ®é›†ï¼Œåœ¨å¾ˆå¤šCVé¢†åŸŸçš„è®ºæ–‡ï¼Œéƒ½ä¼šä½¿ç”¨è¿™ä¸ªæ•°æ®é›†å¯¹è‡ªå·±çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•ï¼Œåœ¨è¯¥é¡¹ç›®ä¸­åˆ†ç±»ç®—æ³•ç”¨åˆ°çš„æµ‹è¯„æ•°æ®é›†å°±æ˜¯ISLVRC2012æ•°æ®é›†çš„éªŒè¯é›†ã€‚åœ¨ä¸€äº›è®ºæ–‡ä¸­ï¼Œä¹Ÿä¼šç§°è¿™ä¸ªæ•°æ®å«æˆImageNet 1Kæˆ–è€…ISLVRC2012ï¼Œä¸¤è€…æ˜¯ä¸€æ ·çš„ã€‚â€œ1 Kâ€ä»£è¡¨çš„æ˜¯1000ä¸ªç±»åˆ«ã€‚

### è¯„ä»·æŒ‡æ ‡è¯´æ˜

- top1å‡†ç¡®ç‡: æµ‹è¯•å›¾ç‰‡ä¸­æœ€ä½³å¾—åˆ†æ‰€å¯¹åº”çš„æ ‡ç­¾æ˜¯æ­£ç¡®æ ‡æ³¨ç±»åˆ«çš„æ ·æœ¬æ•°é™¤ä»¥æ€»çš„æ ·æœ¬æ•°
- top5å‡†ç¡®ç‡: æµ‹è¯•å›¾ç‰‡ä¸­æ­£ç¡®æ ‡ç­¾åŒ…å«åœ¨å‰äº”ä¸ªåˆ†ç±»æ¦‚ç‡ä¸­çš„ä¸ªæ•°é™¤ä»¥æ€»çš„æ ·æœ¬æ•°

## Deploy
ğŸ“ æ³¨ï¼šè¯¥ç½‘ç»œä»…åœ¨`step.1 & step.3`éƒ¨åˆ†æœ‰åŒºåˆ«

### step.1 è·å–æ¨¡å‹

1. timm

    ```bash
    pip install timm==0.6.5
    python ../common/utils/export_timm_torchvision_model.py --model_library timm  --model_name hrnet_w30 --save_dir ./onnx  --size 224 --pretrained_weights xxx.pth
    ```

2. mmclassification

    mmclsæ¡†æ¶å‚è€ƒ [mmclassification](https://github.com/open-mmlab/mmclassification),å¯ä½¿ç”¨å¦‚ä¸‹ä½ç½®çš„pytorch2onnx.pyæˆ–pytorch2torchscript.pyè½¬æˆç›¸åº”çš„æ¨¡å‹

    ```bash
    git clone https://github.com/open-mmlab/mmclassification.git
    cd mmclassification

    python tools/deployment/pytorch2onnx.py \
            --config configs/hrnet/hrnet-w32_4xb32_in1k.py \
            --checkpoint weights/hrnet_w32.pth \
            --output-file output/hrnet_w32.onnx \
    ```

3. official

   è¿›å…¥hrnetå­æ–‡ä»¶å¤¹ï¼Œè¯¥é¡¹ç›®å¯ä»¥å®ç°æ¨¡å‹è½¬æ¢è‡³torchscriptä¸onnxæ ¼å¼ï¼Œè½¬æ¢æ—¶å¯ä»¥æŒ‡å®šæ¨¡å‹è·¯å¾„ä»¥åŠç›¸åº”çš„æ¨¡å‹é…ç½®æ–‡ä»¶ï¼Œè¿è¡Œå‘½ä»¤å¦‚ä¸‹ï¼š

    ```bash
    git clone https://github.com/HRNet/HRNet-Image-Classification.git
    mv source_code/export.py HRNet-Image-Classification
    cd HRNet-Image-Classification

    python tools/export.py --cfg_file experiments/cls_hrnet_w64_sgd_lr5e-2_wd1e-4_bs32_x100.yaml --weight_path /path/to/weights_path --save_name hrnetv2_w64
    ```
### step.2 è·å–æ•°æ®é›†
- æœ¬æ¨¡å‹ä½¿ç”¨ImageNetå®˜ç½‘ILSVRC2012çš„5ä¸‡å¼ éªŒè¯é›†è¿›è¡Œæµ‹è¯•ï¼Œé’ˆå¯¹`int8`æ ¡å‡†æ•°æ®å¯ä»è¯¥æ•°æ®é›†ä¸­ä»»é€‰1000å¼ ï¼Œä¸ºäº†ä¿è¯é‡åŒ–ç²¾åº¦ï¼Œè¯·ä¿è¯æ¯ä¸ªç±»åˆ«éƒ½æœ‰æ•°æ®ï¼Œè¯·ç”¨æˆ·è‡ªè¡Œè·å–è¯¥æ•°æ®é›†ï¼Œ[ILSVRC2012](https://image-net.org/challenges/LSVRC/2012/index.php)

    ```
    â”œâ”€â”€ ImageNet
    |   â”œâ”€â”€ val
    |   |    â”œâ”€â”€ ILSVRC2012_val_00000001.JPEG
    â”‚   |    â”œâ”€â”€ ILSVRC2012_val_00000002.JPEG
    â”‚   |    â”œâ”€â”€ ......
    |   â”œâ”€â”€ val_label.txt
    ```

    ```bash
    sh ./data_prep_sh_files/valprep.sh
    ```

    ```bash
    # label.txt
    tench, Tinca tinca
    goldfish, Carassius auratus
    ...
    ```

### step.3 æ¨¡å‹è½¬æ¢

1. ä½¿ç”¨æ¨¡å‹è½¬æ¢å·¥å…·vamcï¼Œæ ¹æ®å…·ä½“æ¨¡å‹ä¿®æ”¹æ¨¡å‹è½¬æ¢é…ç½®æ–‡ä»¶, æ­¤å¤„ä»¥`timm` ä¸ºä¾‹
    ```bash
    vamc build ./vacc_code/build/timm_hrnet.yaml
    ```
    - [timm](./vacc_code/build/timm_hrnet.yaml)
    - [official](./vacc_code/build/official_hrnet.yaml)
    - [mmcls](./vacc_code/build/mmcls_hrnet.yaml)

### step.4 æ¨¡å‹æ¨ç†
1. æ ¹æ®step.3é…ç½®æ¨¡å‹ä¸‰ä»¶å¥—ä¿¡æ¯ï¼Œ[model_info](./vacc_code/model_info/model_info_hrnet.json)
2. é…ç½®pythonç‰ˆæ•°æ®é¢„å¤„ç†æµç¨‹vdsp_paramså‚æ•°
   - [vdsp_params](./vacc_code/vdsp_params/sdk1.0/timm-hrnet-vdsp_params.json)


3. æ‰§è¡Œæ¨ç†ï¼Œå‚è€ƒ[runstream](../common/sdk1.0/sample_cls.py)
    ```bash
    python ../common/sdk1.0/sample_cls.py --save_dir output/hrnet_result.txt
    ```

4. ç²¾åº¦è¯„ä¼°
   ```bash
    python ../common/eval/eval_topk.py output/hrnet_result.txt
   ```


### step.5 benchmark
1. ç”Ÿæˆæ¨ç†æ•°æ®`npz`ä»¥åŠå¯¹åº”çš„`datalist.txt`
    ```bash
   python ../common/utils/image2npz.py --dataset_path /path/to/ILSVRC2012_img_val --target_path  /path/to/input_npz  --text_path npz_datalist.txt
    ```
2. æ€§èƒ½æµ‹è¯•
    ```bash
    ./vamp -m hrnet_w18-int8-percentile-3_256_256-vacc/hrnet_w18 --vdsp_params ./vacc_code/vdsp_params/vamp/timm-hrnet_w18-vdsp_params.json  -i 1 -p 1 -b 1
    ```
    
3. è·å–ç²¾åº¦ä¿¡æ¯
    ```bash
    ./vamp -m hrnet_w18-int8-percentile-3_256_256-vacc/hrnet_w18 --vdsp_params ./vacc_code/vdsp_params/vamp/timm-hrnet_w18-vdsp_params.json  -i 1 -p 1 -b 1 --datalist npz_datalist.txt --path_output output
    ```
4. ç»“æœè§£æåŠç²¾åº¦è¯„ä¼°
    ```bash
    python ../common/eval/eval_imagenet.py --result_path output  --datalist npz_datalist.txt --label data/label/imagenet.txt
    ```
## appending

æ³¨æ„ï¼š`mmcls`è½¬æ¢ä¸ºonnxæ—¶ï¼Œop_setéœ€è®¾ç½®ä¸º11ï¼Œ10ä¼šæŠ¥é”™ã€‚
