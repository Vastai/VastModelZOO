name: Llama-2-7b-hf
frontend:
  checkpoint: meta-llama/Llama-2-7b-hf
  type: huggingface
  shape:
    input_ids: [[512], [1024]]
  model_kwargs:
    tp: 4
    model_arch: vacc # 优先加载modeling_vacc.py以及config_vacc.json

backend:
  dtype: fp16
  merge_params: true
  compile:
    data_type: 0
    gather_data_vccl_dsp_enable: true

workspace:
  path: ./vamc_results
  workers: 4