# MobiLlama

- [MobiLlama: Towards Accurate and Lightweight Fully Transparent GPT](https://arxiv.org/abs/2402.16840)


## Model Arch
- åŸºäºŽllama2ä¿®æ”¹ï¼Œåœ¨æ¯ä¸€ä¸ªLlamaDecoderLayerå†…å…±äº«åŒä¸€ä»½MLPå‚æ•°

![](../../images/llm/mobillama/arch.png)

## Model Info
### Support Models

| models  | tips |
| :---: | :--: |
| [MobiLlama-05B](https://huggingface.co/collections/MBZUAI/mobillama-65dd4182d588c91e8230332e) |[modelling_mobillama_vacc.py](./source_code/modelling_mobillama_vacc.py) |
| [MobiLlama-05B-Chat](https://huggingface.co/collections/MBZUAI/mobillama-65dd4182d588c91e8230332e) |[modelling_mobillama_vacc.py](./source_code/modelling_mobillama_vacc.py) |
| [MobiLlama-1B](https://huggingface.co/collections/MBZUAI/mobillama-65dd4182d588c91e8230332e) |[modelling_mobillama_vacc.py](./source_code/modelling_mobillama_vacc.py) |
| [MobiLlama-1B-Chat](https://huggingface.co/collections/MBZUAI/mobillama-65dd4182d588c91e8230332e) |[modelling_mobillama_vacc.py](./source_code/modelling_mobillama_vacc.py) |


## Build_In Deploy

### step.1 æ¨¡åž‹å‡†å¤‡

1. å‚è€ƒ`Support Models`åˆ—è¡¨ä¸‹è½½æ¨¡åž‹æƒé‡
2. ç½‘ç»œä¿®æ”¹
    - åŽŸå§‹çš„æ¨¡åž‹æ–‡ä»¶[modeling_mobillama.py#L244](https://github.com/mbzuai-oryx/MobiLlama/blob/main/model_utils/modeling_mobillama.py#L244)ï¼Œä½¿ç”¨äº†`flash_attn_func`å®žçŽ°æ³¨æ„åŠ›æœºåˆ¶ï¼Œéœ€è¦åœ¨æœ‰cudaçŽ¯å¢ƒçš„æœºå™¨ä¸‹è¿è¡Œ
    - æ³¨é‡ŠæŽ‰`flash_attn_func`å®žçŽ°ï¼Œ[modeling_mobillama.py#L214](https://github.com/mbzuai-oryx/MobiLlama/blob/main/model_utils/modeling_mobillama.py#L214)ï¼Œå¼€å¯å…¶ä»£ç å‰é¢çš„å·²æ³¨é‡Šéƒ¨åˆ†ï¼Œä½¿ç”¨torchçš„ç®€å•å®žçŽ°æ›¿ä»£`flash_attn_func`
    - åŽŸå§‹æ¨¡åž‹é…ç½®ä¸­[config.json#L21](https://huggingface.co/MBZUAI/MobiLlama-1B/blob/main/config.json#L21)ï¼Œ`"num_key_value_heads": 4`éœ€è¦æ”¹ä¸º`"num_key_value_heads": 32`ï¼Œå¦åˆ™vamcç¼–è¯‘ä¼šæŠ¥é”™
    - ä¿®æ”¹åŽçš„æ¨¡åž‹æ–‡ä»¶[source_code/modelling_mobillama_vacc.py](./source_code/modelling_mobillama_vacc.py)
    - ä¿®æ”¹åŽçš„æ¨¡åž‹é…ç½®æ–‡ä»¶[source_code/config.json](./source_code/config.json)
    - å°†ä»¥ä¸Šæ–‡ä»¶ç§»åŠ¨è‡³åŽŸå§‹æƒé‡è·¯å¾„å†…ï¼Œè¦†ç›–åŒåæ–‡ä»¶

### step.2 æ•°æ®é›†

1. é‡åŒ–æ ¡å‡†æ•°æ®é›†ï¼š
    - [allenai/c4](https://hf-mirror.com/datasets/allenai/c4/tree/main/en)
        - c4-train.00000-of-01024.json.gz
        - c4-validation.00000-of-00008.json.gz
    - [ceval/ceval-exam](https://hf-mirror.com/datasets/ceval/ceval-exam/tree/main)
        - ceval-exam.zip
    - [yahma/alpaca-cleaned](https://hf-mirror.com/datasets/yahma/alpaca-cleaned/tree/main)
        - alpaca_data_cleaned.json

### step.3 æ¨¡åž‹è½¬æ¢

1. æ ¹æ®å…·ä½“æ¨¡åž‹ä¿®æ”¹æ¨¡åž‹è½¬æ¢é…ç½®æ–‡ä»¶
    - [hf_mobillama_fp16.yaml](./build_in/build/hf_mobillama_fp16.yaml)
    - [hf_mobillama_int8.yaml](./build_in/build/hf_mobillama_int8.yaml)

    > - runstreamæŽ¨ç†ï¼Œç¼–è¯‘å‚æ•°`backend.type: tvm_vacc`
    > - fp16ç²¾åº¦: ç¼–è¯‘å‚æ•°`backend.dtype: fp16`
    > - int8ç²¾åº¦: ç¼–è¯‘å‚æ•°`backend.dtype: int8`

    ```bash
    cd mobillama
    mkdir workspace
    cd workspace
    vamc compile ../build_in/build/hf_mobillama_fp16.yaml
    vamc compile ../build_in/build/hf_mobillama_int8.yaml
    ```

### step.4 æ¨¡åž‹æŽ¨ç†
1. å‚è€ƒå¤§æ¨¡åž‹éƒ¨ç½²æŽ¨ç†å·¥å…·ï¼š[vastgenx](../../tools/vastgenx/README.md)

### Tips
- **LLMæ¨¡åž‹è¯·å…ˆæŸ¥çœ‹æ¦‚è¦æŒ‡å¼•**ï¼Œ[TipsðŸ””](../README.md)
- ä¾èµ–é…ç½®
    ```bash
    protobuf==3.20.3
    torch==2.1.0
    onnx==1.14.0
    onnxsim==0.4.35
    onnxruntime==1.13.1
    accelerate==0.25.0
    transformers>=4.31.0
    ```
