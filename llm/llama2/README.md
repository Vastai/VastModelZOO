# LLaMA2

- Technical Report
    - [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)
    - [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288)
- Huggingface
    - https://huggingface.co/meta-llama


## Model Arch
![llama_arch](../../images/llm/llama/llama_arch.png)

### LLaMA v2
- åœ¨LLaMa1çš„åŸºç¡€ä¸Šï¼Œç»§ç»­å¢åŠ äº†40%çš„é¢„è®­ç»ƒæ•°æ®
    - ä¸»è¦æ˜¯æ¸…ç†äº†ä¸€äº›éšç§æ•°æ®å’ŒçŸ¥è¯†å¢å¼ºä»è€Œæé«˜æ•°æ®è´¨é‡
- ç»§ç»­åœ¨æ¯ä¸ªblockè¾“å…¥å±‚ä¸­ä½¿ç”¨RMSNorm
- ç»§ç»­ä½¿ç”¨RoPEä½ç½®ç¼–ç 
- å¼•å…¥GQA(grouped-query attention)åˆ†ç»„æ³¨æ„åŠ›æœºåˆ¶ï¼Œé€šè¿‡Qåˆ†ç»„ä¸€å®šå¤´æ•°å…±äº«ä¸€ç»„KVï¼Œä»è€Œè¾¾åˆ°æ€§èƒ½å’Œè®¡ç®—ä¸­çš„å¹³è¡¡
- ä½¿ç”¨SiLuæ¿€æ´»å‡½æ•°
- ä½¿ç”¨RLHFè®­ç»ƒè¿‡ç¨‹



## Build_In Deploy

### step.1 æ¨¡å‹å‡†å¤‡

1. ä¸‹è½½æ¨¡å‹æƒé‡

    | models  | tips |
    | :--- | :--: | 
    | [meta-llama/Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf/) | MHA |
    | [meta-llama/Llama-2-7b-chat-hf](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/) | MHA |
    | [meta-llama/Llama-2-13b-hf](https://huggingface.co/meta-llama/Llama-2-13b-hf/) | MHA |
    | [meta-llama/Llama-2-13b-chat-hf](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf/) | MHA |
    | [meta-llama/Llama-2-70b-hf](https://huggingface.co/meta-llama/Llama-2-70b-hf/) | GQA |
    | [meta-llama/Llama-2-70b-chat-hf](https://huggingface.co/meta-llama/Llama-2-70b-chat-hf/) | GQA |

    > - å…¶å®ƒåŸºäº`llama`å¾®è°ƒçš„æ¨¡å‹(`model_type:llama`)ï¼Œè½¬æ¢åŠæ¨ç†æµ‹è¯•å‚è€ƒ`llama`ç³»åˆ—å³å¯
    > - `meta-llama`å¼€æºçš„æ¨¡å‹å‡ä¸æ”¯æŒå•†ç”¨ï¼Œè¯·æŸ¥é˜…åŸå§‹è®¸å¯è¯


### step.2 æ•°æ®é›†

1. é‡åŒ–æ ¡å‡†æ•°æ®é›†ï¼š
    - [allenai/c4](https://hf-mirror.com/datasets/allenai/c4/tree/main/en)
        - c4-train.00000-of-01024.json.gz
        - c4-validation.00000-of-00008.json.gz
    - [ceval/ceval-exam](https://hf-mirror.com/datasets/ceval/ceval-exam/tree/main)
        - ceval-exam.zip
    - [yahma/alpaca-cleaned](https://hf-mirror.com/datasets/yahma/alpaca-cleaned/tree/main)
        - alpaca_data_cleaned.json

### step.3 æ¨¡å‹è½¬æ¢

1. æ ¹æ®å…·ä½“æ¨¡å‹ï¼Œä¿®æ”¹æ¨¡å‹è½¬æ¢é…ç½®æ–‡ä»¶
    - v1/v2/v3æ¨¡å‹ï¼Œç¼–è¯‘é…ç½®ä¸€è‡´
    - [hf_llama2_fp16.yaml](./build_in/build/hf_llama2_fp16.yaml)
    - [hf_llama2_int8.yaml](./build_in/build/hf_llama2_int8.yaml)

    > - runstreamæ¨ç†ï¼Œç¼–è¯‘å‚æ•°`backend.type: tvm_vacc`
    > - fp16ç²¾åº¦: ç¼–è¯‘å‚æ•°`backend.dtype: fp16`
    > - int8ç²¾åº¦: ç¼–è¯‘å‚æ•°`backend.dtype: int8`
    
    ```bash
    vamc compile ./build_in/build/hf_llama2_fp16.yaml
    vamc compile ./build_in/build/hf_llama2_int8.yaml
    ```

### step.4 æ¨¡å‹æ¨ç†
1. å‚è€ƒå¤§æ¨¡å‹éƒ¨ç½²æ¨ç†å·¥å…·ï¼š[vastgenx: v1.1.0+](../../docs/vastgenx/README.md)

### Tips
- **LLMæ¨¡å‹è¯·å…ˆæŸ¥çœ‹æ¦‚è¦æŒ‡å¼•**ï¼Œ[TipsğŸ””](../README.md)
- llamaç³»åˆ—ï¼Œä¸ä¼šå¯¹åŸå§‹llama_modeling.pyè¿›è¡Œä¿®æ”¹ï¼Œä¸ºå…¼å®¹å¤šç‰ˆæœ¬æ¨¡å‹ï¼Œå»ºè®®ä¾èµ–é…ç½®å¦‚ä¸‹ï¼š
    ```bash
    protobuf==3.20.3
    torch==2.1.0
    onnx==1.14.0
    onnxsim==0.4.28
    onnxruntime==1.13.1
    accelerate==0.25.0
    transformers==4.34.0
    ```

## Pytorch Deploy

### step.1 æ¨¡å‹å‡†å¤‡
|  models |    demo_code    |  tips |
| :------ | :------: | :------: |
|[meta-llama/Llama-2-7b-chat-hf](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)|[demo](./pytorch/demo/llama2_7b.py) |  - |

### step.2 æ¨¡å‹æ¨ç†
- åŸºäº`torch_vacc`åœ¨`VA16`ç¡¬ä»¶ä¸‹æ¨ç†ï¼Œä¸€èˆ¬åŸºäºå®˜æ–¹demoè¿›è¡Œé€‚å½“ä¿®æ”¹ï¼Œå‚è§ä¸Šè¡¨`demo_code`éƒ¨åˆ†
