# ChatGLM4

- [GLM: General Language Model Pretraining with Autoregressive Blank Infilling](https://arxiv.org/abs/2103.10360)

## Model Arch

![](../../images/llm/chatglm/chatglm2_arch.png)


## Model Info

### Support Models

| models | tips |
| :---: | :--: |
| [THUDM/glm-4-9b-hf](https://huggingface.co/collections/THUDM/glm-4-665fcf188c414b03c2f7e3b7)  | GQAï¼Œ[modeling_chatglm4_vacc.py](./build_in/source_code/modeling_chatglm4_vacc.py) |
| [THUDM/glm-4-9b-chat-hf](https://huggingface.co/collections/THUDM/glm-4-665fcf188c414b03c2f7e3b7) | GQAï¼Œ[modeling_chatglm4_vacc.py](./build_in/source_code/modeling_chatglm4_vacc.py) |

## TVM_VACCéƒ¨ç½²

### step.1 æ¨¡å‹å‡†å¤‡

1. å‚è€ƒ`Support Models`åˆ—è¡¨ä¸‹è½½æ¨¡å‹æƒé‡
2. ç½‘ç»œä¿®æ”¹
- ä¸ºäº†éƒ¨ç½²chatglm4æ¨¡å‹ï¼Œmodeling_chatglm.pyéœ€è¦é€‚å½“ä¿®æ”¹ï¼Œä¿®æ”¹å[modeling_chatglm4_vacc.py](./build_in/source_code/modeling_chatglm4_vacc.py)
  - 1. CoreAttentionï¼Œé€‚åº”tpåˆ‡åˆ†è°ƒæ•´size
  ![](../../images/chatglm/Snipaste_2024-09-06_16-51-26.png)
  - 2. CoreAttentionï¼Œä½¿ç”¨æ‰‹åŠ¨å®ç°scaled_dot_product_attention
  ![](../../images/chatglm/Snipaste_2024-09-06_16-50-13.png)
  ![](../../images/chatglm/Snipaste_2024-09-06_16-50-43.png)


### step.2 æ•°æ®é›†

1. é‡åŒ–æ ¡å‡†æ•°æ®é›†ï¼š
    - [allenai/c4](https://hf-mirror.com/datasets/allenai/c4/tree/main/en)
        - c4-train.00000-of-01024.json.gz
        - c4-validation.00000-of-00008.json.gz
    - [ceval/ceval-exam](https://hf-mirror.com/datasets/ceval/ceval-exam/tree/main)
        - ceval-exam.zip
    - [yahma/alpaca-cleaned](https://hf-mirror.com/datasets/yahma/alpaca-cleaned/tree/main)
        - alpaca_data_cleaned.json

### step.3 æ¨¡å‹è½¬æ¢
1. æ ¹æ®å…·ä½“æ¨¡å‹ä¿®æ”¹æ¨¡å‹è½¬æ¢é…ç½®æ–‡ä»¶
    - v2/v3/v4æ¨¡å‹ï¼Œç¼–è¯‘é…ç½®ä¸€è‡´
    - [hf_chatglm_fp16.yaml](./build_in/build/hf_chatglm_fp16.yaml)
    - [hf_chatglm_int8.yaml](./build_in/build/hf_chatglm_int8.yaml)
    - [hf_chatglm_kv8.yaml](./build_in/build/hf_chatglm_kv8.yaml)

    > - runstreamæ¨ç†ï¼Œç¼–è¯‘å‚æ•°`backend.type: tvm_vacc`
    > - fp16ç²¾åº¦: ç¼–è¯‘å‚æ•°`backend.dtype: fp16`
    > - int8ç²¾åº¦: ç¼–è¯‘å‚æ•°`backend.dtype: int8`

    ```bash
    vamc compile ./build_in/build/hf_chatglm_fp16.yaml
    vamc compile ./build_in/build/hf_chatglm_int8.yaml
    vamc compile ./build_in/build/hf_chatglm_kv8.yaml
    ```


### step.4 æ¨¡å‹æ¨ç†
1. å‚è€ƒå¤§æ¨¡å‹éƒ¨ç½²æ¨ç†å·¥å…·ï¼š[vastgenx: v1.1.0+](../../docs/vastgenx/README.md)

    **Note:** åŸºäº[benchmark_llm.sh](../../docs/vastgenx/script/benchmarks/benchmark_llm.sh)æµ‹è¯•æ€§èƒ½æ—¶ï¼Œéœ€ä¿®æ”¹`benchmark_serveing.py`ä¼ å…¥çš„å‚æ•°ï¼Œå³æ·»åŠ `â€“-trust_remote_code`ã€`--backend "openai-chat"`ä¿®æ”¹ä¸º`--backend "openai"`


### Tips
- **LLMæ¨¡å‹è¯·å…ˆæŸ¥çœ‹æ¦‚è¦æŒ‡å¼•**ï¼Œ[TipsğŸ””](../README.md)
- ä¾èµ–é…ç½®
    ```bash
    protobuf==3.20.3
    torch==2.1.0
    onnx==1.14.0
    onnxsim==0.4.35
    onnxruntime==1.13.1
    accelerate==0.25.0
    transformers>=4.31.0 # æ¨è4.40
    tiktoken
    ```
