# ChatGLM2

- [GLM: General Language Model Pretraining with Autoregressive Blank Infilling](https://arxiv.org/abs/2103.10360)

## Model Arch

![](../../images/llm/chatglm/chatglm2_arch.png)

## Model Info

### Support Models

| models  | tips |
| :---: | :--: |
| [THUDM/chatglm2-6b](https://huggingface.co/THUDM/chatglm2-6b) | GQAï¼Œ[modeling_chatglm2_vacc.py](./source_code/modeling_chatglm2_vacc.py) |


## Build_In Deploy

### step.1 æ¨¡å‹å‡†å¤‡

1. å‚è€ƒ`Support Models`åˆ—è¡¨ä¸‹è½½æ¨¡å‹æƒé‡
2. ç½‘ç»œä¿®æ”¹
- ä¸ºäº†æ–¹ä¾¿éƒ¨ç½²`ChatGLM`ç³»åˆ—æ¨¡å‹ï¼Œåœ¨å®˜æ–¹æºç åŸºç¡€ä¸Šï¼Œå¯¹`modeling_chatglm.py`åšäº†ä¸€äº›ä¿®æ”¹ï¼Œå…·ä½“ä¿®æ”¹å¦‚ä¸‹ï¼Œ å…¶ä¸­å·¦å›¾ä¸ºä¿®æ”¹çš„ä»£ç 
- [modeling_chatglm2_vacc.py](./source_code/modeling_chatglm2_vacc.py)

  - 1. CoreAttentionï¼Œé€‚åº”tpåˆ‡åˆ†è°ƒæ•´sizeï¼Œä¸åŒºåˆ†torchç‰ˆæœ¬ï¼Œ ç»Ÿä¸€`forward`å‡½æ•°

  ![](../../images/llm/chatglm/coreatten_init.png)

  - 2. sliceï¼Œæ’å…¥sliceï¼Œ ä¼˜åŒ–æ¨ç†

  ![](../../images/llm/chatglm/slice.png)

  - 3. quantizationï¼Œä¿®æ”¹ quantization.pyï¼Œä»…å½“é‡åŒ–æ–¹å¼ä¸ºå®˜æ–¹é»˜è®¤æ—¶ä¿®æ”¹ï¼Œ vamc-gptqä¸éœ€è¦
    ```python
    # ç±»W8A16Linearæ–°å¢symbolicå‡½æ•°ç”¨äºæ³¨å†Œè‡ªå®šä¹‰ç®—å­å¯¼å‡ºonnx
    class W8A16Linear(torch.autograd.Function):

    + @staticmethod
    + def symbolic(
    + 	g: torch._C.Graph,
    + 	input: torch._C.Value,
    + 	quant_w: torch._C.Value,
    + 	scale_w: torch._C.Value,
    + 	weight_bit_width:torch._C.Value,
    + ):
    + 	from torch.onnx.symbolic_helper import _get_tensor_sizes, _get_tensor_dim_size
    + 	# print('_get_tensor_sizes(input)===', _get_tensor_sizes(input))
    + 	# print('_get_tensor_sizes(quant_w)===', _get_tensor_sizes(quant_w))
    + 	opr_type = input.type().with_sizes(_get_tensor_sizes(input)[:-1] + [_get_tensor_sizes(quant_w)[0],])
    + 	ret = g.op("Vastai::QuantizedLinearPerChannel", input, quant_w, scale_w).setType(opr_type)
    + 	return ret


    # å‡½æ•°extract_weight_to_half æ³¨é‡Šassert cpuç”¨fp32
    def extract_weight_to_half
    - assert scale_list.dtype in [torch.half, torch.bfloat16]
    + # assert scale_list.dtype in [torch.half, torch.bfloat16]

    # å‡½æ•° quantize æ³¨é‡Š torch.cuda.current_device()

    ```
- ä¸ºäº†éƒ¨ç½²chatglm2-kv8æ¨¡å‹ï¼Œ modeling.pyä»¥ä¸Šä¿®æ”¹çš„åŸºç¡€ä¸Šæ·»åŠ å¯¹past_key_valueçš„ä¿®æ”¹ï¼Œ æ–°å¢ä¿®æ”¹å¦‚ä¸‹
- [modeling_chatglm2_vacc.py](./source_code/modeling_chatglm2_vacc.py)
  - 1. kv_cache é‡åŒ–ä¸åé‡åŒ–å‡½æ•°å®šä¹‰

  ![](../../images/llm/chatglm/quant_func_1.png)

  ![](../../images/llm/chatglm/quant_func_2.png)

  - 2. ä»configè·å– kvcache quant æ‰€éœ€å‚æ•°

  ![](../../images/llm/chatglm/gen_init.png)

  - 4. kv_cacheåé‡åŒ–ä¸é‡åŒ–

  ![](../../images/llm/chatglm/gen_add_dequant.png)

  ![](../../images/llm/chatglm/gen_add_quant.png)


### step.2 æ•°æ®é›†

1. é‡åŒ–æ ¡å‡†æ•°æ®é›†ï¼š
    - [allenai/c4](https://hf-mirror.com/datasets/allenai/c4/tree/main/en)
        - c4-train.00000-of-01024.json.gz
        - c4-validation.00000-of-00008.json.gz
    - [ceval/ceval-exam](https://hf-mirror.com/datasets/ceval/ceval-exam/tree/main)
        - ceval-exam.zip
    - [yahma/alpaca-cleaned](https://hf-mirror.com/datasets/yahma/alpaca-cleaned/tree/main)
        - alpaca_data_cleaned.json

### step.3 æ¨¡å‹è½¬æ¢
1. æ ¹æ®å…·ä½“æ¨¡å‹ä¿®æ”¹æ¨¡å‹è½¬æ¢é…ç½®æ–‡ä»¶
    - v2/v3/v4æ¨¡å‹ï¼Œç¼–è¯‘é…ç½®ä¸€è‡´
    - [hf_chatglm_fp16.yaml](./build_in/build/hf_chatglm_fp16.yaml)
    - [hf_chatglm_int8.yaml](./build_in/build/hf_chatglm_int8.yaml)
    - [hf_chatglm_kv8.yaml](./build_in/build/hf_chatglm_kv8.yaml)

    > - runstreamæ¨ç†ï¼Œç¼–è¯‘å‚æ•°`backend.type: tvm_vacc`
    > - fp16ç²¾åº¦: ç¼–è¯‘å‚æ•°`backend.dtype: fp16`
    > - int8ç²¾åº¦: ç¼–è¯‘å‚æ•°`backend.dtype: int8`
    
    ```bash
    cd chatglm2
    mkdir workspace
    cd workspace
    vamc compile ../build_in/build/hf_chatglm_fp16.yaml
    vamc compile ../build_in/build/hf_chatglm_int8.yaml
    vamc compile ../build_in/build/hf_chatglm_kv8.yaml
    ```


### step.4 æ¨¡å‹æ¨ç†
1. å‚è€ƒå¤§æ¨¡å‹éƒ¨ç½²æ¨ç†å·¥å…·ï¼š[vastgenx](../../docs/vastgenx/README.md)


### Tips
- **LLMæ¨¡å‹è¯·å…ˆæŸ¥çœ‹æ¦‚è¦æŒ‡å¼•**ï¼Œ[TipsğŸ””](../README.md)
- ä¾èµ–é…ç½®
    ```bash
    protobuf==3.20.3
    torch==2.1.0
    onnx==1.14.0
    onnxsim==0.4.35
    onnxruntime==1.13.1
    accelerate==0.25.0
    transformers>=4.31.0 # æ¨è4.40
    tiktoken
    ```
