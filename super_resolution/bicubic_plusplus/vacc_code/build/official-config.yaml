model:
  name: bicubic_plusplus_2x
  inputs:
    input: [1, 3, 1080, 1920]
  checkpoint: bicubic_plusplus_2x.torchscript.pt

engine:
  type: vacc
  dtype: int8
  common:
    data_transport_mode: 1
  add_extra_ops_to_graph:
    type: null
  calibration:
    calibrate_mode: kl_divergence
    quantize_per_channel: true

dataset:
  path: /media/temp/DIV2K/DIV2K_valid_LR_bicubic/X2
  sampler:
    suffix: null
    get_data_num: 100
  transform_ops:
    - type: DecodeImage
    - type: Resize
      size: [1080, 1920]
    - type: Normalize
      norm_type: null
    - type: ToTensor

workspace:
  work_dir: ./deploy_weights/
  enable_ir: true
  save_log: true


# cd /home/simplew/code/vamc/vamp/2.1.0


# 需要设置 enable_graph_partition: false


# pretrained/bicubic_pp_x3.torchscript.pt 640 3X

# (base) simplew@simplew-OptiPlex-7090:~/code/vamc/vamp/2.1.0$ ./vamp_2.1.0 -m /home/simplew/code/vastmodelzoo/0818/algorithm_modelzoo/deploy_weights/bicubic_pp_x3-int8-max-1_3_640_640-vacc/mod
#  --vdsp_params /home/simplew/code/vastmodelzoo/0818/algorithm_modelzoo/super_resolution/rcan/vacc_code/vdsp_params/official-rcan-vdsp_params.json -i 1 p 1 -b 1
# LoadLibrary VaclBatchInferTensor from /opt/vastai/vastpipe/vastpipe/calculators/libVaclBatchInferTensor.so
# version_path: /opt/vastai/vastpipe/vastpipe/version
# VastPipe Version: 2.2.5
# load model and init graph...
# [15305]: Initializing VACM logger with config: /var/log/vastai/fnlog/vslog.cfg.
# [16:27:28] /opt/soft/ai-compiler-test-scripts/vastai/vaststream/tvm/src/runtime/graph/vacc_infer_module.cc:524: ssram not enough, use ddr for dlc output, max batch size only 1.
# [16:27:28] /opt/soft/ai-compiler-test-scripts/vastai/vaststream/tvm/src/runtime/graph/vacc_infer_module.cc:524: ssram not enough, use ddr for dlc output, max batch size only 1.
# model input shape 0: [3,640,640], dtype: u1
# load model and init graph done
# - number of instances in each device: 1
#   devices: [0]
#   batch size: 1
#   ai utilize (%): 94.3895
#   temperature (°C): 48.2419
#   card power (W): 32.8045
#   die memory used (MB): 1436.59
#   throughput (qps): 52.9789
#   e2e latency (us):
#     avg latency: 47042
#     min latency: 22200
#     max latency: 59665
#     p50 latency: 40817
#     p90 latency: 56537
#     p95 latency: 56580
#     p99 latency: 56654
#   model latency (us):
#     avg latency: 47001
#     min latency: 22192
#     max latency: 59659
#     p50 latency: 40809
#     p90 latency: 56496
#     p95 latency: 56529
#     p99 latency: 56593


# (base) simplew@simplew-OptiPlex-7090:~/code/vamc/vamp/2.1.0$ ./vamp_2.1.0 -m /home/simplew/code/vastmodelzoo/0818/algorithm_modelzoo/deploy_weights/bicubic_pp_x3-int8-percentile-1_3_1080_1920-vacc/mod --vdsp_params /home/simplew/code/vastmodelzoo/0818/algorithm_modelzoo/super_resolution/rcan/vacc_code/vdsp_params/official-rcan-vdsp_params.json -i 1 p 1 -b 1
# LoadLibrary VaclBatchInferTensor from /opt/vastai/vastpipe/vastpipe/calculators/libVaclBatchInferTensor.so
# version_path: /opt/vastai/vastpipe/vastpipe/version
# VastPipe Version: 2.2.5
# load model and init graph...
# [4143]: Initializing VACM logger with config: /var/log/vastai/fnlog/vslog.cfg.
# [12:42:56] /opt/soft/ai-compiler-test-scripts/vastai/vaststream/tvm/src/runtime/graph/vacc_infer_module.cc:524: ssram not enough, use ddr for dlc output, max batch size only 1.
# [12:42:56] /opt/soft/ai-compiler-test-scripts/vastai/vaststream/tvm/src/runtime/graph/vacc_infer_module.cc:524: ssram not enough, use ddr for dlc output, max batch size only 1.
# model input shape 0: [3,1080,1920], dtype: u1
# load model and init graph done
# - number of instances in each device: 1
#   devices: [0]
#   batch size: 1
#   ai utilize (%): 88.6355
#   temperature (°C): 46.2209
#   card power (W): 32.5533
#   die memory used (MB): 2332.59
#   throughput (qps): 10.4588
#   e2e latency (us):
#     avg latency: 238786
#     min latency: 109245
#     max latency: 300206
#     p50 latency: 204450
#     p90 latency: 286836
#     p95 latency: 286889
#     p99 latency: 286991
#   model latency (us):
#     avg latency: 238732
#     min latency: 109193
#     max latency: 300152
#     p50 latency: 204388
#     p90 latency: 286787
#     p95 latency: 286831
#     p99 latency: 286928


# (base) simplew@simplew-OptiPlex-7090:~/code/vamc/vamp/2.1.0$ ./vamp_2.1.0 -m /home/simplew/code/vastmodelzoo/0818/algorithm_modelzoo/deploy_weights/bicubic_pp_x2_32-int8-kl_divergence-1_3_1080_1920-vacc/mod --vdsp_params /home/simplew/code/vastmodelzoo/0818/algorithm_modelzoo/super_resolution/rcan/vacc_code/vdsp_params/official-rcan-vdsp_params.json -i 1 p 1 -b 1
# LoadLibrary VaclBatchInferTensor from /opt/vastai/vastpipe/vastpipe/calculators/libVaclBatchInferTensor.so
# version_path: /opt/vastai/vastpipe/vastpipe/version
# VastPipe Version: 2.2.5
# load model and init graph...
# [32700]: Initializing VACM logger with config: /var/log/vastai/fnlog/vslog.cfg.
# [19:24:06] /opt/soft/ai-compiler-test-scripts/vastai/vaststream/tvm/src/runtime/graph/vacc_infer_module.cc:524: ssram not enough, use ddr for dlc output, max batch size only 1.
# [19:24:06] /opt/soft/ai-compiler-test-scripts/vastai/vaststream/tvm/src/runtime/graph/vacc_infer_module.cc:524: ssram not enough, use ddr for dlc output, max batch size only 1.
# model input shape 0: [3,1080,1920], dtype: u1
# load model and init graph done
# - number of instances in each device: 1
#   devices: [0]
#   batch size: 1
#   ai utilize (%): 94.8172
#   temperature (°C): 47.3399
#   card power (W): 37.0211
#   die memory used (MB): 1644.59
#   throughput (qps): 97.2483
#   e2e latency (us):
#     avg latency: 25578
#     min latency: 18515
#     max latency: 38818
#     p50 latency: 28624
#     p90 latency: 30722
#     p95 latency: 30754
#     p99 latency: 30814
#   model latency (us):
#     avg latency: 25536
#     min latency: 18460
#     max latency: 38768
#     p50 latency: 28553
#     p90 latency: 30678
#     p95 latency: 30706
#     p99 latency: 30760

# (base) simplew@simplew-OptiPlex-7090:~/code/vamc/vamp/2.1.0$ ./vamp_2.1.0 -m /home/simplew/code/vastmodelzoo/0818/algorithm_modelzoo/deploy_weights/Bicubic_plus_plus_x2_38_net_g_1577600-int8-max-1_3_1080_1920-vacc/mod --vdsp_params /home/simplew/code/vastmodelzoo/0818/algorithm_modelzoo/super_resolution/rcan/vacc_code/vdsp_params/official-rcan-vdsp_params.json -i 1 p 1 -b 1
# LoadLibrary VaclBatchInferTensor from /opt/vastai/vastpipe/vastpipe/calculators/libVaclBatchInferTensor.so
# version_path: /opt/vastai/vastpipe/vastpipe/version
# VastPipe Version: 2.2.5
# load model and init graph...
# [28755]: Initializing VACM logger with config: /var/log/vastai/fnlog/vslog.cfg.
# [18:33:49] /opt/soft/ai-compiler-test-scripts/vastai/vaststream/tvm/src/runtime/graph/vacc_infer_module.cc:524: ssram not enough, use ddr for dlc output, max batch size only 1.
# [18:33:49] /opt/soft/ai-compiler-test-scripts/vastai/vaststream/tvm/src/runtime/graph/vacc_infer_module.cc:524: ssram not enough, use ddr for dlc output, max batch size only 1.
# model input shape 0: [3,1080,1920], dtype: u1
# load model and init graph done
# - number of instances in each device: 1
#   devices: [0]
#   batch size: 1
#   ai utilize (%): 95.8148
#   temperature (°C): 48.1828
#   card power (W): 36.6924
#   die memory used (MB): 1676.6
#   throughput (qps): 67.3153
#   e2e latency (us):
#     avg latency: 37044
#     min latency: 22165
#     max latency: 51655
#     p50 latency: 36774
#     p90 latency: 44546
#     p95 latency: 44591
#     p99 latency: 44662
#   model latency (us):
#     avg latency: 36996
#     min latency: 22159
#     max latency: 51649
#     p50 latency: 36767
#     p90 latency: 44498
#     p95 latency: 44537
#     p99 latency: 44613